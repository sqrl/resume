<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="style.css" type="text/css" />
</head>
<body>
<h1 id="milo-polte">Milo Polte</h1>
<hr />
<table>
<colgroup>
<col width="51%" />
<col width="48%" />
</colgroup>
<tbody>
<tr class="odd">
<td><code>762 Shotwell St</code></td>
<td align="right"><code>milo.polte@gmail.com</code></td>
</tr>
<tr class="even">
<td><code>San Francisco, CA 94110</code></td>
<td align="right"><code>github.com/sqrl (mostly professional)</code></td>
</tr>
<tr class="odd">
<td><code>Phone: 607-280-3615</code></td>
<td align="right"><code>github.com/hyena (mostly hobbies)</code></td>
</tr>
<tr class="even">
<td><code>www.linkedin.com/in/milopolte</code></td>
<td align="right"><code>This resume's source code:</code> <a href="https://github.com/sqrl/resume" class="uri">https://github.com/sqrl/resume</a></td>
</tr>
</tbody>
</table>
<hr />
<h2 id="work-experience">Work Experience</h2>
<dl>
<dt>Jan 2017 - April 2020</dt>
<dd><p><em>Senior Software Engineer at <a href="https://tracegenomics.com/">TraceGenomics Inc.</a></em> (Burlingame, Californa)</p>
<ul>
<li>Designed and implemented the backend pipeline and software stack for analyzing genomic information using parallel computing, reducing compute time from days to minutes.</li>
<li>Advised and mentored the engineering team as the most senior engineer for 3 years.</li>
<li>Optimized cloud computing to save over 70% per month on compute costs.</li>
<li>Acted as the security engineer on the team; deployed security practices and firewall infrastructure, investigated hacking and phishing attempts, managed company accounts.</li>
</ul>
</dd>
<dt>May 2015 - Dec 2016</dt>
<dd><p><em>Software Engineer at <a href="https://www.dropbox.com">Dropbox</a> in the Data Infrastructure Team</em> (San Francisco).</p>
<ul>
<li>Tech lead on new data-infra APIs, replacing single point of failure web-forms with programmatic interfaces providing the backends for a new suite of analytic tools.
<ul>
<li>Query Service: A RESTful API for Hive and Presto queries.</li>
<li>ETL Service: A RESTful API for safely managing job pipelines.</li>
</ul></li>
<li>Member of an on-call rotation maintaining an infrastructure that runs thousands of jobs crunching petabytes of log data.</li>
</ul>
</dd>
<dt>Jan 2012 - Feb 2015</dt>
<dd><p><em>Software Engineer and Manager/Tech Lead for <a href="https://www.wibidata.com">WibiData, Inc</a></em> (San Francisco).</p>
<ul>
<li>Fourth employee at a Big Data startup that grew to over forty.</li>
<li>Developed a platform for personalized applications on top of Hadoop, HBase, and Cassandra.
<ul>
<li>Our platform was used in production to deliver real-time product recommendations at two large retail customers, including holiday traffic.</li>
</ul></li>
<li>Project/tech lead on the effort to open source our software stack as the <a href="https://github.com/kijiproject">Kiji Project</a>.
<ul>
<li>Broke down the effort into manageable, prioritized tasks for the team, delivering tested, first releases on schedule.</li>
<li>Kiji permitted us to better engage with our community with our own meet-ups, etc.</li>
<li>Tech lead on our earliest real time scoring component, <a href="https://github.com/kijiproject/kiji-scoring">Kiji Scoring</a> that served our first real time recommendations.</li>
</ul></li>
<li><p>Transitioned to a dual technical-managerial role and managed ten direct reports during my tenure (a maximum of five at one time).</p></li>
<li>Tech Lead/Manager of the platform team.
<ul>
<li>Responsible for the foundational layers of our stack.</li>
<li>Developed and help design internal build tools and scripts that reduced compile time and improved engineer productivity.</li>
</ul></li>
</ul>
</dd>
<dt>Summer 2011</dt>
<dd><p><em>Software Engineer internship at <a href="http://www.panasas.com/">Panasas</a></em> (Pittsburgh, PA).</p>
<ul>
<li>Project work towards instrumenting a FreeBSD kernel driver to implement QoS I/O scheduling in network attached storage devices for our parallel, distributed filesystem.</li>
</ul>
</dd>
</dl>
<h2 id="technologies-and-skills">Technologies and Skills</h2>
<p>I've used a variety of technologies and programming languages, but here I highlight a few and describe what I've used them for in work and play. For any language or technology I probably have &quot;strong opinions weakly held&quot; about what's great and awful about them.</p>
<dl>
<dt>Python</dt>
<dd><p>I've used python at just about every company for scripting as well as systems coding.</p>
<ul>
<li>Wrote data pipelines of workers running bioinformatics on a queue of work items</li>
<li>Slack bots for alerting and integrations with external services such as Google sheets</li>
<li>Authored devtools and simple but helpful build components, e.g. <a href="https://github.com/sqrl/packrat">packrat</a> which we used internally at WibiData to cache and share build artifacts.</li>
<li>Worked on large Python-based backend systems such as Dropbox's Python based blockstore service and our 'Drone' job scheduler for Hadoop jobs.</li>
</ul>
</dd>
<dt>Java</dt>
<dd>I am experienced in coding distributed applications and map-reduce programs in Java. For example, it's what I used primarily at Dropbox for our new Data APIs written as DropWizard applications.
</dd>
<dt>Hadoop Stack</dt>
<dd><p>I've used a variety of technologies in the Hadoop ecosystem for model training and analytics: MapReduce, Yarn, HBase, Hive, Scalding, etc.</p>
<ul>
<li>Ported Wibi's ecosystem to different versions of the Cloudera Distribution of Hadoop and others, dealing with the bugs and changes along the way.</li>
<li>Debugged numerous grungy issues in HBase ecosystem, such as ZooKeeper references, unblocking coworkers.</li>
<li>Put in yet more grunge-work hours on Dropbox's giant Hive cluster, migrating namenodes on a live cluster, debugging subtle Zookeeper locks, etc.</li>
</ul>
</dd>
<dt>Amazon Web Services</dt>
<dd><p>At TraceGenomics, we used Amazon's cloud platform for most of our infrastructure</p>
<ul>
<li>Administered IAM user permissions as well as EC2 role-based access to sensitive credentials.</li>
<li>Profiled performance requirements of different bioinformatic workers to efficiently size instances for company's needs.</li>
<li>Led periodic reviews of our expenses, planning and executing steps to reduce our costs.</li>
</ul>
</dd>
<dt>Scrum and hygienic coding</dt>
<dd><p>I was one of the first scrum masters at WibiData. Everyone does it differently.</p>
<ul>
<li>Led Sprint Planning for Wibi's platform team, working with Product to prioritize tasks.</li>
<li>Established much of our culture of code reviews, tooling, etc.</li>
<li>Owned the effort on writing our Python style guide.</li>
<li>At TraceGenomics introduced our first implementations of sprint planning and code reviews.</li>
</ul>
</dd>
<dt>Rust</dt>
<dd><p>Still learning this technology, but I'm really excited about its potential for critical, low level code.</p>
<ul>
<li>Coded a number of slack and discord bots to practice Rust:
<ul>
<li>https://github.com/hyena/gnoll-roll Discord dice bot</li>
<li>https://github.com/hyena/blood-money Webapp in Rust that pulled real time auction house data from the World of Warcraft API and advised on trade good prices for players. Handled thousands of requests per day at its height. Defunct now.</li>
<li>https://github.com/hyena/professor_sloak Bot that gives people random pokemon on request, fortune cookie style.</li>
</ul></li>
</ul>
</dd>
</dl>
<h2 id="education">Education</h2>
<dl>
<dt>2006-2011</dt>
<dd><p><em>Masters Degree in Computer Science with partial work towards a PhD at Carnegie Mellon University</em> (Pittsburgh, PA)</p>
<p>Advisor: Garth Gibson.</p>
<ul>
<li>Conducted research in CMU’s Parallel Data Lab group under the programs of the <a href="http://www.pdsi-scidac.org/">Petascale Data Storage Institute</a> and the <a href="http://institute.lanl.gov/isti/irhpit">Institute For Reliable High Performance Information Technology</a>.</li>
<li>Benchmarked Flash-based SSDs and evaluated cost efficiency of different hybrid configurations. Papers: <a href="http://www.pdl.cmu.edu/PDL-FTP/PDSI/simsa-pdsw08.pdf" class="uri">http://www.pdl.cmu.edu/PDL-FTP/PDSI/simsa-pdsw08.pdf</a> and <a href="http://www.pdl.cmu.edu/PDL-FTP/PDSI/Polte.pdf" class="uri">http://www.pdl.cmu.edu/PDL-FTP/PDSI/Polte.pdf</a>. Included work inside the Linux kernel.</li>
<li>Collaborated with Los Alamos National Laboratory in the design and implementation of the <a href="http://institutes.lanl.gov/plfs/">Parallel Log-structured File System</a>. Papers: <a href="http://institutes.lanl.gov/plfs/plfs.pdf" class="uri">http://institutes.lanl.gov/plfs/plfs.pdf</a> and <a href="http://www.pdsi-scidac.org/events/PDSW09/resources/pdsw09-final9.pdf" class="uri">http://www.pdsi-scidac.org/events/PDSW09/resources/pdsw09-final9.pdf</a></li>
<li>Investigated the design of parallel filesystems for HPC built on top of BigTable-like software. Paper: <a href="http://www.cs.cmu.edu/~svp/2009hotcloud-tablefs.pdf" class="uri">http://www.cs.cmu.edu/~svp/2009hotcloud-tablefs.pdf</a></li>
</ul>
</dd>
<dt>1999-2005</dt>
<dd><p><em>Bachelor of Arts and Master of Engineering in Computer Science at Cornell University</em> (Ithaca, NY)</p>
<p>Emphasis on courses in Distributed Systems, Networks, and Theory.</p>
<ul>
<li>Independent Research with Prof. Emin Gun Sirer - (2001- 2002) Researched and developed an anonymizing peer-to-peer overlay network based on dining cryptographer nets called ‘Herbivore’. White paper: <a href="http://www.cs.cornell.edu/People/egs/herbivore" class="uri">http://www.cs.cornell.edu/People/egs/herbivore</a></li>
<li>Cornell University Neurobiology Department - (2005) Worked as a software engineer on an audio research and education workbench program called “Koé”, providing functionality similar to professional synthesis applications, such as Reaktor.</li>
</ul>
</dd>
</dl>
<h2 id="hobbies-and-other-activities">Hobbies and Other Activities</h2>
<ul>
<li><a href="http://i.imgur.com/ApbbKi8.jpg">Hiking</a></li>
<li><a href="http://markbittman.com/book/how-to-cook-everything-vegetarian/">Vegetarian Cooking</a></li>
<li>My pet <a href="https://www.youtube.com/watch?v=SzU_dGHykZ4">rabbit</a></li>
</ul>
</body>
</html>
